{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fe27d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jilln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jilln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Text preprocessing (NLTK)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e893a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Subfield</th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have experience in full-stack development an...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I focus on building scalable software solution...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I specialize in data science, working with Ten...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I enjoy using statistical methods and algorith...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have experience in writing clean, efficient ...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Programmer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text          Subfield  \\\n",
       "0  I have experience in full-stack development an...  Computer Science   \n",
       "1  I focus on building scalable software solution...  Computer Science   \n",
       "2  I specialize in data science, working with Ten...  Computer Science   \n",
       "3  I enjoy using statistical methods and algorith...  Computer Science   \n",
       "4  I have experience in writing clean, efficient ...  Computer Science   \n",
       "\n",
       "                   Job Title  \n",
       "0          Software Engineer  \n",
       "1          Software Engineer  \n",
       "2  Machine Learning Engineer  \n",
       "3  Machine Learning Engineer  \n",
       "4                 Programmer  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/ict_subfields_dataset.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64d01b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Processed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have experience in full-stack development an...</td>\n",
       "      <td>experience fullstack development work javascri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I focus on building scalable software solution...</td>\n",
       "      <td>focus building scalable software solution opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I specialize in data science, working with Ten...</td>\n",
       "      <td>specialize data science working tensorflow ker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I enjoy using statistical methods and algorith...</td>\n",
       "      <td>enjoy using statistical method algorithm solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have experience in writing clean, efficient ...</td>\n",
       "      <td>experience writing clean efficient code langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love solving complex problems through progra...</td>\n",
       "      <td>love solving complex problem programming optim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I enjoy developing backend services and APIs u...</td>\n",
       "      <td>enjoy developing backend service apis using py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Building scalable and maintainable application...</td>\n",
       "      <td>building scalable maintainable application som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I like implementing machine learning algorithm...</td>\n",
       "      <td>like implementing machine learning algorithm f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Experimenting with deep learning frameworks li...</td>\n",
       "      <td>experimenting deep learning framework like pyt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  I have experience in full-stack development an...   \n",
       "1  I focus on building scalable software solution...   \n",
       "2  I specialize in data science, working with Ten...   \n",
       "3  I enjoy using statistical methods and algorith...   \n",
       "4  I have experience in writing clean, efficient ...   \n",
       "5  I love solving complex problems through progra...   \n",
       "6  I enjoy developing backend services and APIs u...   \n",
       "7  Building scalable and maintainable application...   \n",
       "8  I like implementing machine learning algorithm...   \n",
       "9  Experimenting with deep learning frameworks li...   \n",
       "\n",
       "                                      Processed_Text  \n",
       "0  experience fullstack development work javascri...  \n",
       "1  focus building scalable software solution opti...  \n",
       "2  specialize data science working tensorflow ker...  \n",
       "3  enjoy using statistical method algorithm solve...  \n",
       "4  experience writing clean efficient code langua...  \n",
       "5  love solving complex problem programming optim...  \n",
       "6  enjoy developing backend service apis using py...  \n",
       "7  building scalable maintainable application som...  \n",
       "8  like implementing machine learning algorithm f...  \n",
       "9  experimenting deep learning framework like pyt...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    This function preprocesses the input text by performing the following operations:\n",
    "    \n",
    "    1. **Lowercasing**: Converts all characters in the text to lowercase to ensure uniformity. \n",
    "       This step is crucial for text normalization, as words like \"Apple\" and \"apple\" should be treated the same.\n",
    "    \n",
    "    2. **Removing Punctuation**: Eliminates all punctuation characters (e.g., commas, periods, question marks) \n",
    "       to avoid them interfering with the processing of words. This is done using string translation and the `string.punctuation` module.\n",
    "\n",
    "    3. **Removing Numbers**: Removes any numerical digits that appear in the text using a regular expression (`\\d+`), \n",
    "       which matches any sequence of digits. This is helpful if numbers aren't relevant for the task (e.g., in sentiment analysis).\n",
    "\n",
    "    4. **Removing Extra Whitespace**: Consolidates any consecutive spaces into a single space and strips leading/trailing spaces.\n",
    "       This is done with a regular expression (`\\s+`) to ensure the text is properly spaced and doesn't contain unwanted gaps.\n",
    "\n",
    "    5. **Removing Stopwords**: Eliminates common words that don't provide much value in analysis, such as \"the\", \"is\", \"and\", etc.\n",
    "       This is accomplished using a predefined list of stopwords from the `nltk.corpus.stopwords` module.\n",
    "\n",
    "    6. **Lemmatization**: Reduces words to their base form or root word. For example, \"running\" becomes \"run\", and \"better\" becomes \"good\". \n",
    "       This step ensures that similar words are treated as the same, which is particularly useful for tasks like text classification and sentiment analysis.\n",
    "    \n",
    "    The function returns the cleaned and preprocessed text as output, which is ready for further analysis or modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    # Lemmatize the text\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'Text' column and create a new column 'Processed_Text'\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Preview the result\n",
    "df[['Text', 'Processed_Text']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ae12c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '10 usc' '103' '103 volunteer' '15277' '15277 may' '1599f' '15k'\n",
      " '15k hiring' '1832150' '1832150 may' '25218b' '25218b temp' '256th'\n",
      " '256th intelligence' '2d3d' '2d3d animation' '32' '32 excepted'\n",
      " '32 position']\n",
      "Accuracy: 0.6521739130434783\n",
      "Classification Report:\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                      Computer Science       0.67      0.22      0.33         9\n",
      "Entertainment and Multimedia Computing       0.60      1.00      0.75         3\n",
      "                                    IT       0.55      0.86      0.67         7\n",
      "                   Information Systems       1.00      1.00      1.00         3\n",
      "       Library and Information Science       1.00      1.00      1.00         1\n",
      "\n",
      "                              accuracy                           0.65        23\n",
      "                             macro avg       0.76      0.82      0.75        23\n",
      "                          weighted avg       0.68      0.65      0.61        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer with bigrams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # unigrams and bigrams\n",
    "\n",
    "# Transform the processed text into bigram features\n",
    "X = vectorizer.fit_transform(df['Processed_Text'])\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Subfield']\n",
    ")  # Replace 'Label' with your actual label column name\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(vectorizer.get_feature_names_out()[:20])  # First 20 bigram features\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4af3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jilln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jilln\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # Optional but recommended for WordNet's multilingual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10e6bad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar subfield is: Entertainment and Multimedia Computing\n",
      "Recommended job: Technical Animator\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming df is your dataset and user_input is the string provided by the user\n",
    "\n",
    "# Function to preprocess user input (same as your preprocessing function)\n",
    "def preprocess_user_input(user_input):\n",
    "    return preprocess_text(user_input)  # Assuming preprocess_text is defined as before\n",
    "\n",
    "# Preprocess the user input\n",
    "user_input = \"I like animation and digital art.\"  # Example user input\n",
    "processed_user_input = preprocess_user_input(user_input)\n",
    "\n",
    "# Vectorize the user input using the same vectorizer used for the dataset\n",
    "user_input_vector = vectorizer.transform([processed_user_input])  # Transform into TF-IDF vector\n",
    "\n",
    "# Vectorize the entire dataset (assuming 'Processed_Text' column is preprocessed)\n",
    "dataset_vectors = vectorizer.transform(df['Processed_Text'])\n",
    "\n",
    "# Compute the cosine similarity between the user input vector and the dataset vectors\n",
    "cosine_similarities = cosine_similarity(user_input_vector, dataset_vectors)\n",
    "\n",
    "# Find the index of the most similar document in the dataset\n",
    "most_similar_index = np.argmax(cosine_similarities)\n",
    "\n",
    "# Retrieve the corresponding label (subfield) from the dataset\n",
    "most_similar_subfield = df['Subfield'].iloc[most_similar_index]\n",
    "\n",
    "# Retrieve the recommended job for the matched subfield\n",
    "subfield_jobs = {\n",
    "    'Computer Science': 'Software Engineer',\n",
    "    'Computer Science': 'Machine Learning Engineer',\n",
    "    'Computer Science': 'Programmer',\n",
    "    'Information Technology': 'Network Administrator',\n",
    "    'Information Technology': 'System Analyst',\n",
    "    'Information Technology': 'Cybersecurity Expert',\n",
    "    'Information Systems': 'Business Analyst',\n",
    "    'Information Systems': 'IT Project Manager',\n",
    "    'Information Systems': 'ERP Specialist',\n",
    "    'Entertainment and Multimedia Computing': 'Game Developer',\n",
    "    'Entertainment and Multimedia Computing': 'Multimedia Artist',\n",
    "    'Entertainment and Multimedia Computing': 'Technical Animator',\n",
    "    'Library and Information Science': 'Digital Librarian',\n",
    "    'Library and Information Science': 'Information Architect',\n",
    "    'Library and Information Science': 'Records Manager'\n",
    "}\n",
    "\n",
    "recommended_job = subfield_jobs.get(most_similar_subfield, \"Job recommendation not found.\")\n",
    "\n",
    "# Output the most similar subfield and the recommended job\n",
    "print(f\"The most similar subfield is: {most_similar_subfield}\")\n",
    "print(f\"Recommended job: {recommended_job}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b4ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
